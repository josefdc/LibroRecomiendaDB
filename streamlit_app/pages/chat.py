# streamlit_app/pages/chat.py

import streamlit as st
import uuid # Para generar IDs de conversaci칩n 칰nicos
from langchain_core.messages import AIMessage, HumanMessage
import logging

# Configurar logging b치sico para Streamlit (opcional pero 칰til)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Importa tu grafo compilado (aseg칰rate que la ruta sea correcta)
try:
    # Aseg칰rate de que la importaci칩n refleje la estructura de tu proyecto
    # Si graph.py est치 en src/librorecomienda/agents/graph.py
    # y streamlit_app est치 al mismo nivel que src/, necesitas ajustar el sys.path o usar rutas relativas correctas
    # Una forma com칰n es a침adir src al path si ejecutas streamlit desde la ra칤z
    import sys
    import os
    # A침ade el directorio 'src' al path si no est치 ya
    src_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'src'))
    if src_path not in sys.path:
        sys.path.insert(0, src_path)

    from librorecomienda.agents.graph import graph, CRUD_AVAILABLE # Asume que 'graph' es el objeto compilado y CRUD_AVAILABLE indica si las tools est치n listas
    logger.info("Grafo del agente importado correctamente.")
    if not CRUD_AVAILABLE:
        logger.warning("Las funciones CRUD no est치n disponibles. Las herramientas del agente no funcionar치n.")

except ImportError as e:
    logger.error(f"Error al importar el grafo del agente: {e}", exc_info=True)
    st.error(f"No se pudo importar el grafo del agente. Aseg칰rate de que la ruta sea correcta y las dependencias est칠n instaladas. Error: {e}")
    st.stop()
except AttributeError as e:
     logger.error(f"Error de atributo al importar: {e}", exc_info=True)
     st.error(f"Aseg칰rate de que 'graph' (el grafo compilado con checkpointer) est칠 disponible y exportado correctamente en agents/graph.py. Error: {e}")
     st.stop()
except Exception as e:
    logger.error(f"Error inesperado durante la importaci칩n: {e}", exc_info=True)
    st.error(f"Ocurri칩 un error inesperado al cargar el agente: {e}")
    st.stop()


# --- T칤tulo de la P치gina ---
st.set_page_config(page_title="Chat de Recomendaciones", page_icon="游눫") # Configura t칤tulo e icono de la pesta침a
st.title("游눫 Chat de Recomendaciones")
st.caption("Habla con nuestro agente para encontrar tu pr칩xima lectura.")

# --- Inicializaci칩n del Estado de Sesi칩n del Chat ---
# Usamos claves espec칤ficas para este chat para no interferir con otros estados
if "chat_thread_id" not in st.session_state:
    # Cada nueva sesi칩n de chat obtiene un ID 칰nico
    st.session_state.chat_thread_id = str(uuid.uuid4())
    logger.info(f"Nueva sesi칩n de chat iniciada con thread_id: {st.session_state.chat_thread_id}")
    st.session_state.chat_messages = [
        AIMessage(content="춰Hola! Soy tu asistente de recomendaciones de libros. 쯈u칠 tipo de libros te interesan?")
    ]
# --- Fin Inicializaci칩n ---


# --- Mostrar Historial de Mensajes ---
# Itera sobre los mensajes guardados en el estado de sesi칩n y mu칠stralos
for msg in st.session_state.chat_messages:
    if isinstance(msg, AIMessage):
        st.chat_message("assistant", avatar="游뱄").write(msg.content)
    elif isinstance(msg, HumanMessage):
        st.chat_message("user", avatar="游녻").write(msg.content)
# --- Fin Mostrar Historial ---


# --- Entrada del Usuario y Ejecuci칩n del Agente ---
if prompt := st.chat_input("Escribe tu mensaje aqu칤..."):
    # 1. A침adir y mostrar el mensaje del usuario
    st.session_state.chat_messages.append(HumanMessage(content=prompt))
    st.chat_message("user", avatar="游녻").write(prompt)
    logger.info(f"Usuario (Thread: {st.session_state.chat_thread_id}): {prompt}")

    # 2. Preparar configuraci칩n para LangGraph (con el thread_id de esta sesi칩n)
    config = {"configurable": {"thread_id": st.session_state.chat_thread_id}}

    # 3. Llamar al agente (grafo LangGraph)
    # Prepara el input para el grafo (solo el 칰ltimo mensaje humano es necesario
    # si el historial completo est치 en 'messages' dentro del estado del grafo)
    # Nota: El estado interno del grafo ('messages') es manejado por el checkpointer.
    # Aqu칤 solo pasamos el nuevo input.
    inputs = {"messages": [HumanMessage(content=prompt)]}

    # Muestra un indicador de espera mientras el agente procesa
    with st.chat_message("assistant", avatar="游뱄"):
        with st.spinner("Pensando..."):
            try:
                # Llama al grafo usando stream para obtener la respuesta final
                # Usamos stream_mode="values" para obtener el estado final completo
                final_state = None
                logger.debug(f"Llamando al grafo con input: {inputs} y config: {config}")
                # Aumentar el l칤mite de recursi칩n si es necesario para grafos complejos
                # CORRECCI칍N: Eliminar recursion_limit=25 ya que no es un argumento v치lido para stream
                for chunk in graph.stream(inputs, config=config, stream_mode="values"):
                    # El 칰ltimo chunk contendr치 el estado final despu칠s de la ejecuci칩n
                    logger.debug(f"Chunk recibido del stream: {chunk.keys()}") # Ver qu칠 nodos se ejecutan
                    final_state = chunk

                logger.debug(f"Estado final recibido del grafo: {final_state}")

                # 4. Extraer y mostrar la 칰ltima respuesta del AI
                if final_state and "messages" in final_state and final_state["messages"]:
                    # La respuesta del AI es el 칰ltimo mensaje en la lista del estado final
                    ai_response_message = final_state["messages"][-1]
                    if isinstance(ai_response_message, AIMessage):
                        response_content = ai_response_message.content
                        # Asegurarse de que no sea una respuesta vac칤a o solo de llamada a herramienta
                        if response_content and not ai_response_message.tool_calls:
                            st.markdown(response_content) # Mostrar la respuesta
                            # 5. A침adir respuesta del AI al historial de sesi칩n (para mostrar)
                            st.session_state.chat_messages.append(ai_response_message)
                            logger.info(f"Agente (Thread: {st.session_state.chat_thread_id}): {response_content}")
                        elif ai_response_message.tool_calls:
                             logger.info(f"Agente (Thread: {st.session_state.chat_thread_id}): Realiz칩 llamada a herramienta.")
                             # Podr칤as poner un mensaje placeholder o simplemente no a침adir nada visible si la llamada a herramienta es interna
                             # st.markdown("Estoy buscando informaci칩n...") # Opcional
                             # No a침adir la llamada a herramienta como mensaje visible
                        else:
                            logger.warning("El 칰ltimo mensaje del agente AI estaba vac칤o.")
                            st.error("El agente devolvi칩 una respuesta vac칤a.")
                            st.session_state.chat_messages.append(AIMessage(content="Lo siento, no pude generar una respuesta clara."))

                    else:
                        logger.error(f"El 칰ltimo mensaje no fue AIMessage: {type(ai_response_message)}")
                        st.error("El agente no devolvi칩 un mensaje de AI v치lido.")
                        st.session_state.chat_messages.append(AIMessage(content="Lo siento, tuve un problema con el formato de la respuesta."))
                else:
                     logger.error(f"El estado final no conten칤a 'messages' o estaba vac칤o: {final_state}")
                     st.error("El agente no devolvi칩 una respuesta.")
                     st.session_state.chat_messages.append(AIMessage(content="Lo siento, no pude generar una respuesta."))

            except Exception as e:
                logger.error(f"Error durante la ejecuci칩n del grafo en Streamlit (Thread: {st.session_state.chat_thread_id}): {e}", exc_info=True)
                st.error(f"Ocurri칩 un error al procesar tu solicitud: {e}")
                # A침adir un mensaje de error al historial de chat
                st.session_state.chat_messages.append(AIMessage(content=f"Lo siento, ocurri칩 un error interno: {e}"))


# --- Fin Entrada del Usuario ---

# --- (Opcional) Bot칩n para limpiar historial de la sesi칩n actual ---
if st.button("Limpiar historial de chat"):
    st.session_state.chat_messages = [
        AIMessage(content="춰Hola! 쯉obre qu칠 tipo de libros te gustar칤a hablar hoy?")
    ]
    # OJO: Esto NO limpia el estado del checkpointer (MemorySaver).
    # Para limpiar MemorySaver, necesitar칤as reiniciar el proceso Streamlit
    # o implementar l칩gica espec칤fica si usaras un checkpointer persistente.
    # Podr칤amos generar un NUEVO thread_id para simular un reinicio completo:
    # st.session_state.chat_thread_id = str(uuid.uuid4())
    # logger.info(f"Historial de chat limpiado. Nuevo thread_id: {st.session_state.chat_thread_id}")
    st.rerun()
